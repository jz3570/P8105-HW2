---
title: "p8105_hw2_jz3570"
author: "Jiawen Zhao"
date: "9/29/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

```{r}
library(tidyverse)

options(tibble.print_min = 3)

NYC_Data <- read.csv("~/Desktop/P8105/HW2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
NYC_Data <- janitor::clean_names(NYC_Data)
NYC_Data_filter = select(NYC_Data, line, station_name, station_latitude, station_longitude, contains('route'), entry, vending, entrance_type, ada)
# line, station_name, station_latitude, station_longitude, routes served, entry, vending, entrance_type, ada
NYC_Data_filter$entry <- as.factor(NYC_Data_filter$entry)
NYC_Data_filter$vending <- as.factor(NYC_Data_filter$vending)
NYC_Data_filter$station_name <- as.factor(NYC_Data_filter$station_name)
distinct_station = distinct(NYC_Data_filter,line,station_name)
ada = filter(NYC_Data_filter, ada == TRUE)
ada_distinct_station = distinct(ada,line,station_name)
entry_vending = filter(NYC_Data_filter, entry == "YES" & vending == "NO")
entry_vending_station = distinct(entry_vending,line,station_name)

#rowSums("A" == NYC_Data_filter) > 0 
distinct_A =
  mutate(NYC_Data_filter,
    A = rowSums("A" == NYC_Data_filter) > 0 
  )

A_train = filter(distinct_A, A == TRUE)
A_train_station = distinct(A_train,line,station_name)
A_train_ada = filter(A_train, ada == TRUE)
A_train_ada_station = distinct(A_train_ada,line,station_name)

pulse_data = NYC_Data_filter
pulse_data[5:15] = lapply(pulse_data[5:15], FUN = function(y){as.character(y)})
pulse_tidy_data = 
  pivot_longer(
    pulse_data, 
    route1:route11,
    names_to = "route", 
    values_to = "line code")
#Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

## the dataset now contains variables including line, station_name, station_latitude, station_longitude, routes served, entry, vending, entrance_type, ada.  

## Answer the following questions using these data:

## How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.
## How many stations are ADA compliant?
## What proportion of station entrances / exits without vending allow entrance?
## Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?


```

## The raw dataset has 32 columns (variables) and 1868 rows (observations). After selecting only the variables we need, the dataset has 19 columns (variables) and 1868 rows (observations). While selecting the routes served, we used the parameter contain() to select all the columns contain "route". Then, we change the data type of column "entry" from character to factors. THe dataset now is tidier than the raw dataset, but we can make further improvements too.

## There are 465 distinct stations
 
## Among those distinct stations, there are 84 stations that are ada compliant. If not only look at the distinct stations, but also look at the duplicated stations, there are 468 stations that are ada compliant.

## There are 43/186 of distinct stations having entry without vending. If not only look at the distinct stations, but also look at the duplicated stations, there are 43/186 of stations having entry without vending.

## There are 4 distinct stations serve the A train. Of the stations that serve the A train, 3 stations are ADA compliant.




## Problem 2


```{r}
library(readxl)
Trash_Wheel_m <- read_excel("Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel")
Trash_Wheel_m <- janitor::clean_names(Trash_Wheel_m)
#Trash_Wheel_m = na.omit(Trash_Wheel_m)
head(Trash_Wheel_m, 5)
Trash_Wheel_m = Trash_Wheel_m[1:(length(Trash_Wheel_m)-2)]
Trash_Wheel_m = na.omit(Trash_Wheel_m, dumpster)
Trash_Wheel_m$sports_balls = round(Trash_Wheel_m$sports_balls)
Trash_Wheel_m$sports_balls = as.integer(Trash_Wheel_m$sports_balls)
Trash_Wheel_m$sheet_type = "Mr. Trash Wheel"
```


```{r}
library(readxl)
Trash_Wheel_p <- read_excel("Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel")
Trash_Wheel_p <- janitor::clean_names(Trash_Wheel_p)
#Trash_Wheel_p = na.omit(Trash_Wheel_p)
head(Trash_Wheel_p, 5)
#Trash_Wheel_p = Trash_Wheel_p[1:(length(Trash_Wheel_p)-3)]
Trash_Wheel_p = na.omit(Trash_Wheel_p, dumpster)
# Trash_Wheel_p$sports_balls = round(Trash_Wheel_p$sports_balls)
# Trash_Wheel_p$sports_balls = as.integer(Trash_Wheel_p$sports_balls)
# Trash_Wheel_p$dumpster = as.character(Trash_Wheel_p$dumpster)
Trash_Wheel_p$year = as.character(Trash_Wheel_p$year)
Trash_Wheel_p$sheet_type = "Professor Trash Wheel"
Trash_Wheel_p$sports_balls = (NA)
```


```{r}
Trash_Wheel = full_join(Trash_Wheel_m,Trash_Wheel_p)
Trash_Wheel_ans_m = filter(Trash_Wheel, sheet_type == "Mr. Trash Wheel" & year == 2020)
sum(Trash_Wheel_ans_m$sports_balls)
Trash_Wheel_ans_p = filter(Trash_Wheel, sheet_type == "Professor Trash Wheel")
sum(Trash_Wheel_ans_p$weight_tons)

```

# The answer data frame is Trash_Wheel. Firstly, the data frames reads the professor sheet and mr. trash sheet separately. The professor datarame has 95 observations and 13 variables. The mr trash data frame has 548 observations and 16 variables. After processing them aby using functions like `as.character`, `filter`, `mutate`, I add a colum sports ball to professor data frame so that we can use full join to combine these two data frames. The final dataframe, Trash_Wheel, has 629 observations and 15 variables, such as month, year, day, plastic bottles, etc.

## The total weight of trash collected by Professor Trash Wheel is 162.54 (ton). The total number of sports balls collected by Mr. Trash Wheel in 2020 is 856.

# Problem 3

```{r}
# pols-month.csv, unemployment.csv, and snp.csv
library(tidyverse)

options(tibble.print_min = 3)

pols.month <- read.csv("~/Desktop/P8105/HW2/fivethirtyeight_datasets/pols-month.csv")
unemployment <- read.csv("~/Desktop/P8105/HW2/fivethirtyeight_datasets/unemployment.csv")
snp <- read.csv("~/Desktop/P8105/HW2/fivethirtyeight_datasets/snp.csv")
unemployment = janitor::clean_names(unemployment)

```

```{r}
pols.month = 
  read.csv("~/Desktop/P8105/HW2/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = '-')
# month to month.abb
pols.month$month <- month.abb[as.numeric(pols.month$month)]
#new column-president
pols.month = mutate(pols.month, president = case_when(prez_dem == 1 ~ 'dem',
  prez_gop == 1 ~ 'gop'))%>%
  select(-prez_dem, -prez_gop, -day)


```

```{r}
snp <- read.csv("~/Desktop/P8105/HW2/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  select(year, month, close) 
  
# month to month.abb
snp$month <- month.abb[as.numeric(snp$month)]

snp$year <- format(as.Date(as.character(snp$year), format="%y"),"%Y")

```


```{r}
unemployment$year = as.character(unemployment$year)

unemployment = 
  pivot_longer(
    unemployment, 
    jan:dec,
    names_to = "month", 
    values_to = "unemployment")


ans = left_join(pols.month, snp, by = c('year','month'))
ans = left_join(ans, unemployment, by = c('year','month'))

## Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset

## Firstly, it reads pols-month.csv as a data frame, pols.month, where it has 822 observations of 9 variables related to the number of national politicians who are democratic or republican for each day. I use `seperate` function to split the date into year, month, day. Then, combine the binary columns of rep/dem party into one column. Secondly, it reads snp data set as snp and it contains 787 observations of 2 variables related to Standard & Poor’s stock market index. Similarly, I use `seperate` function to split the date into year, month, day. Then, it reads unemployment.csv as unemployment data set. It contains 68 observations of 13 variables. Then, I use pivot_longer to combines month as a variable, instead of 12 variables. Finally, I conbines all three data frames by using left join based on the year and month. The final data frame ans has 822 observations and 11 variables, inclusing year, month, gov_gop, president, unemployment, etc. Year range from 1947 to 2015.
```


